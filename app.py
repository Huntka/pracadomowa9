import streamlit as st
import os
import json
from openai import OpenAI
from langfuse import Langfuse
from langfuse import observe
import pickle
import pandas as pd

# --------------------------------------------------------------------------------
# Konfiguracja Aplikacji
# --------------------------------------------------------------------------------

st.set_page_config(
    page_title="Kalkulator Czasu P√≥≈Çmaratonu",
    page_icon="üèÉ‚Äç‚ôÄÔ∏è"
)

st.title("üèÉ‚Äç‚ôÄÔ∏è Szacowany czas uko≈Ñczenia p√≥≈Çmaratonu")
st.markdown("""
Wpisz poni≈ºej kilka s≈Ç√≥w o sobie: podaj sw√≥j wiek, p≈Çeƒá oraz typowe tempo biegu na 5 km. 
Nasza AI przeanalizuje tekst, a model postara siƒô oszacowaƒá Tw√≥j czas w p√≥≈Çmaratonie!
""")

# --------------------------------------------------------------------------------
# Panel boczny (Sidebar) do wprowadzania kluczy API
# --------------------------------------------------------------------------------

with st.sidebar:
    st.header("üîê Konfiguracja API")
    st.markdown("Wprowad≈∫ swoje klucze API, aby uruchomiƒá aplikacjƒô.")

    # Pole na klucz OpenAI
    openai_api_key = st.text_input(
        "Klucz API OpenAI",
        type="password",
        help="Mo≈ºesz go znale≈∫ƒá na https://platform.openai.com/api-keys"
    )

    st.divider()

    st.subheader("Langfuse (Opcjonalnie)")
    # Pola na klucze Langfuse
    langfuse_public_key = st.text_input("Langfuse Public Key", type="password")
    langfuse_secret_key = st.text_input("Langfuse Secret Key", type="password")
    langfuse_host = st.text_input("Langfuse Host URL", value="https://cloud.langfuse.com")

# Inicjalizacja klienta Langfuse, je≈õli klucze sƒÖ dostƒôpne
langfuse = None
if langfuse_public_key and langfuse_secret_key:
    try:
        langfuse = Langfuse(
            public_key=langfuse_public_key,
            secret_key=langfuse_secret_key,
            host=langfuse_host
        )
        st.sidebar.success("Po≈ÇƒÖczono z Langfuse!")
    except Exception as e:
        st.sidebar.error(f"B≈ÇƒÖd po≈ÇƒÖczenia z Langfuse: {e}")

# Sprawdzenie, czy klucz OpenAI zosta≈Ç wprowadzony
if not openai_api_key:
    st.warning("Proszƒô wprowadziƒá klucz API OpenAI w panelu bocznym, aby kontynuowaƒá.")
    st.stop()

# Inicjalizacja klienta OpenAI
client = OpenAI(api_key=openai_api_key)

# --------------------------------------------------------------------------------
# Funkcje pomocnicze
# --------------------------------------------------------------------------------

@observe(name="data_extraction") # Dekorator Langfuse do ≈õledzenia wywo≈Çania
def extract_runner_data(user_description: str) -> dict:
    """
    U≈ºywa modelu GPT do wyekstrahowania danych biegacza z tekstu.

    Args:
        user_description: Tekst wprowadzony przez u≈ºytkownika.

    Returns:
        S≈Çownik (dict) z wyekstrahowanymi danymi lub pusty s≈Çownik w razie b≈Çƒôdu.
    """
    system_prompt = """
    Twoim zadaniem jest precyzyjne wyekstrahowanie trzech informacji z tekstu podanego przez u≈ºytkownika:
    1.  `wiek` (jako liczba ca≈Çkowita)
    2.  `p≈Çeƒá` (jako string: "Kobieta" lub "Mƒô≈ºczyzna")
    3.  `tempo_5km` (jako liczba zmiennoprzecinkowa, w minutach na kilometr, np. 6.5 dla 6:30 min/km)

    Zwr√≥ƒá odpowied≈∫ WY≈ÅƒÑCZNIE w formacie JSON, kt√≥ry zawiera te trzy klucze.
    Je≈õli kt√≥rej≈õ informacji brakuje, przypisz jej warto≈õƒá null.
    Przyk≈Çad: {"wiek": 35, "p≈Çeƒá": "Mƒô≈ºczyzna", "tempo_5km": 5.75}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_description}
            ]
        )
        # Parsowanie odpowiedzi JSON
        extracted_data = json.loads(response.choices[0].message.content)
        return extracted_data
    except Exception as e:
        st.error(f"WystƒÖpi≈Ç b≈ÇƒÖd podczas komunikacji z API OpenAI: {e}")
        return {}

# --- MIEJSCE NA M√ìJ MODEL ---
import boto3
import pickle
import pandas as pd
import os

# Funkcja do pobrania i wczytania modelu z chmury
@st.cache_resource
def load_model_from_space():
    try:
        # Pobieramy klucze ze zmiennych ≈õrodowiskowych serwera ---
        DO_SPACES_ACCESS_KEY = os.environ.get("DO_SPACES_ACCESS_KEY")
        DO_SPACES_SECRET_KEY = os.environ.get("DO_SPACES_SECRET_KEY")
        DO_SPACES_ENDPOINT_URL = os.environ.get("DO_SPACES_ENDPOINT_URL")
        DO_SPACES_BUCKET_NAME = os.environ.get("DO_SPACES_BUCKET_NAME")
        MODEL_FILE_NAME = "marathon_model.pkl"

        # Tworzymy klienta s3
        session = boto3.session.Session()
        s3_client = session.client('s3',
                                   endpoint_url=DO_SPACES_ENDPOINT_URL,
                                   aws_access_key_id=DO_SPACES_ACCESS_KEY,
                                   aws_secret_access_key=DO_SPACES_SECRET_KEY)
        
        # Pobieramy plik modelu z chmury do pamiƒôci podrƒôcznej aplikacji
        s3_client.download_file(DO_SPACES_BUCKET_NAME, MODEL_FILE_NAME, f"/tmp/{MODEL_FILE_NAME}")
        
        # Wczytujemy pobrany plik z folderu tymczasowego
        with open(f"/tmp/{MODEL_FILE_NAME}", 'rb') as file:
            model = pickle.load(file)
        return model

    except Exception as e:
        st.error(f"B≈ÇƒÖd podczas ≈Çadowania modelu z chmury: {e}")
        return None

# Wczytujemy model
model = load_model_from_space()

# --- ZMIANA W KLIENCIE OPENAI ---
# Aplikacja w chmurze automatycznie u≈ºyje zmiennej OPENAI_API_KEY
client = OpenAI()

def predict_time(age: int, gender: str, pace_5k: float) -> str:
    """
    U≈ºywa wczytanego modelu do przewidywania czasu p√≥≈Çmaratonu.
    """
    if model is None:
        return "B≈ÇƒÖd: Model nie jest za≈Çadowany."

    gender_mapped = 'K' if gender.lower().startswith('k') else 'M'

    input_data = pd.DataFrame({
        'Age': [age],
        'Gender': [gender_mapped],
        'Pace_5k': [pace_5k]
    })

    predicted_seconds = model.predict(input_data)[0]

    hours = int(predicted_seconds // 3600)
    minutes = int((predicted_seconds % 3600) // 60)
    seconds = int(predicted_seconds % 60)

    return f"{hours:02d}:{minutes:02d}:{seconds:02d}"
# --- KONIEC MIEJSCA NA MODEL ---


# --------------------------------------------------------------------------------
# G≈Ç√≥wny interfejs aplikacji
# --------------------------------------------------------------------------------

user_input = st.text_area(
    "Opowiedz nam o sobie:",
    height=150,
    placeholder="Np. 'Cze≈õƒá, jestem Ania, mam 28 lat. Biegam od roku, a moje tempo na 5 km to oko≈Ço 6 minut na kilometr.'"
)

if st.button("Szacuj czas p√≥≈Çmaratonu", type="primary"):
    if user_input:
        with st.spinner("Analizujƒô Twoje dane i liczƒô... ü§ñ"):
            # Krok 1: Ekstrakcja danych za pomocƒÖ LLM
            extracted_data = extract_runner_data(user_input)

            if not extracted_data:
                st.error("Nie uda≈Ço siƒô przetworzyƒá danych. Spr√≥buj ponownie.")
            else:
                # Krok 2: Walidacja wyekstrahowanych danych
                missing_info = []
                if extracted_data.get("wiek") is None:
                    missing_info.append("wiek")
                if extracted_data.get("p≈Çeƒá") is None:
                    missing_info.append("p≈Çeƒá")
                if extracted_data.get("tempo_5km") is None:
                    missing_info.append("tempo na 5 km")

                if missing_info:
                    st.warning(f"**Niestety, nie znalaz≈Çem wszystkich potrzebnych informacji.**\n\nBrakuje mi: **{', '.join(missing_info)}**.\n\nSpr√≥buj opisaƒá siebie jeszcze raz, bardziej szczeg√≥≈Çowo.")
                else:
                    # Krok 3: Wywo≈Çanie modelu predykcyjnego
                    age = extracted_data["wiek"]
                    gender = extracted_data["p≈Çeƒá"]
                    pace_5k = extracted_data["tempo_5km"]

                    st.info(f"**Wyekstrahowane dane:**\n- Wiek: **{age}**\n- P≈Çeƒá: **{gender}**\n- Tempo na 5km: **{pace_5k} min/km**")

                    predicted_time = predict_time(age, gender, pace_5k)
                    
                    # Krok 4: Wy≈õwietlenie wyniku
                    st.success(f"### Tw√≥j szacowany czas na p√≥≈Çmaraton to: **{predicted_time}**")
                    st.balloons()
                    
                    # Opcjonalne ≈õledzenie w Langfuse
                    if langfuse:
                        langfuse.flush() # Wys≈Çanie zebranych danych do Langfuse
                        st.sidebar.info("Dane z ekstrakcji LLM zosta≈Çy zapisane w Langfuse.")
    else:
        st.warning("Proszƒô wpisaƒá kilka s≈Ç√≥w o sobie w polu tekstowym.")